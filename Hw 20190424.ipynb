{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND = tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000,784)\n",
    "x_test = x_test.reshape(10000,784 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_105 (Dense)            (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 150)               30150     \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 10)                1510      \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 228,860\n",
      "Trainable params: 228,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(200,input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(150))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='mse',optimizer=SGD(lr=0.01),metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.0912 - acc: 0.0989 - val_loss: 0.0906 - val_acc: 0.0987\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0904 - acc: 0.1060 - val_loss: 0.0902 - val_acc: 0.1192\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0900 - acc: 0.1747 - val_loss: 0.0899 - val_acc: 0.1941\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0898 - acc: 0.1729 - val_loss: 0.0898 - val_acc: 0.1579\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0897 - acc: 0.1490 - val_loss: 0.0896 - val_acc: 0.1423\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0896 - acc: 0.1363 - val_loss: 0.0896 - val_acc: 0.1375\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0895 - acc: 0.1349 - val_loss: 0.0895 - val_acc: 0.1365\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0895 - acc: 0.1359 - val_loss: 0.0895 - val_acc: 0.1349\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0894 - acc: 0.1304 - val_loss: 0.0894 - val_acc: 0.1399\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0894 - acc: 0.1349 - val_loss: 0.0894 - val_acc: 0.1434\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0893 - acc: 0.1428 - val_loss: 0.0893 - val_acc: 0.1432\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0893 - acc: 0.1443 - val_loss: 0.0892 - val_acc: 0.1452\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0892 - acc: 0.1456 - val_loss: 0.0892 - val_acc: 0.1499\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0892 - acc: 0.1452 - val_loss: 0.0891 - val_acc: 0.1585\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0891 - acc: 0.1561 - val_loss: 0.0891 - val_acc: 0.1622\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0891 - acc: 0.1564 - val_loss: 0.0890 - val_acc: 0.1668\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0890 - acc: 0.1623 - val_loss: 0.0890 - val_acc: 0.1738\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0890 - acc: 0.1646 - val_loss: 0.0889 - val_acc: 0.1798\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0889 - acc: 0.1763 - val_loss: 0.0889 - val_acc: 0.1799\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0889 - acc: 0.1809 - val_loss: 0.0888 - val_acc: 0.1802\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0888 - acc: 0.1771 - val_loss: 0.0888 - val_acc: 0.1864\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0887 - acc: 0.1818 - val_loss: 0.0887 - val_acc: 0.1928\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0887 - acc: 0.1908 - val_loss: 0.0886 - val_acc: 0.1965\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0886 - acc: 0.1906 - val_loss: 0.0886 - val_acc: 0.2020\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0886 - acc: 0.1938 - val_loss: 0.0885 - val_acc: 0.2076\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0885 - acc: 0.1987 - val_loss: 0.0885 - val_acc: 0.2127\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0884 - acc: 0.2077 - val_loss: 0.0884 - val_acc: 0.2135\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0884 - acc: 0.2089 - val_loss: 0.0883 - val_acc: 0.2154\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0883 - acc: 0.2109 - val_loss: 0.0883 - val_acc: 0.2188\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0883 - acc: 0.2128 - val_loss: 0.0882 - val_acc: 0.2246\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0882 - acc: 0.2173 - val_loss: 0.0881 - val_acc: 0.2293\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0881 - acc: 0.2251 - val_loss: 0.0881 - val_acc: 0.2296\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0881 - acc: 0.2250 - val_loss: 0.0880 - val_acc: 0.2329\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0880 - acc: 0.2263 - val_loss: 0.0879 - val_acc: 0.2408\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0879 - acc: 0.2333 - val_loss: 0.0878 - val_acc: 0.2438\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0878 - acc: 0.2384 - val_loss: 0.0877 - val_acc: 0.2445\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0877 - acc: 0.2382 - val_loss: 0.0877 - val_acc: 0.2488\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0877 - acc: 0.2427 - val_loss: 0.0876 - val_acc: 0.2518\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0876 - acc: 0.2482 - val_loss: 0.0875 - val_acc: 0.2524\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0875 - acc: 0.2516 - val_loss: 0.0874 - val_acc: 0.2531\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0874 - acc: 0.2475 - val_loss: 0.0873 - val_acc: 0.2609\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0873 - acc: 0.2551 - val_loss: 0.0872 - val_acc: 0.2639\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0872 - acc: 0.2575 - val_loss: 0.0871 - val_acc: 0.2699\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0871 - acc: 0.2645 - val_loss: 0.0870 - val_acc: 0.2708\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0870 - acc: 0.2664 - val_loss: 0.0869 - val_acc: 0.2716\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0869 - acc: 0.2662 - val_loss: 0.0868 - val_acc: 0.2794\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0868 - acc: 0.2734 - val_loss: 0.0867 - val_acc: 0.2805\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0867 - acc: 0.2757 - val_loss: 0.0866 - val_acc: 0.2811\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0866 - acc: 0.2752 - val_loss: 0.0865 - val_acc: 0.2871\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0865 - acc: 0.2809 - val_loss: 0.0863 - val_acc: 0.2891\n"
     ]
    }
   ],
   "source": [
    "model_out=model.fit(x_train, y_train, batch_size=100, epochs=50,verbose =1,validation_data = (x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_73 (Dense)             (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 150)               30150     \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 10)                1510      \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 228,860\n",
      "Trainable params: 228,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(200,input_dim=784))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dense(200))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dense(150))\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "model2.add(Dense(10))\n",
    "model2.add(Activation('softmax'))\n",
    "model2.compile(loss='mse',optimizer=SGD(lr=0.01),metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1465 - acc: 0.2585 - val_loss: 0.1294 - val_acc: 0.3463\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1272 - acc: 0.3561 - val_loss: 0.1255 - val_acc: 0.3648\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1252 - acc: 0.3658 - val_loss: 0.1249 - val_acc: 0.3677\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.1244 - acc: 0.3702 - val_loss: 0.1251 - val_acc: 0.3677\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.1238 - acc: 0.3734 - val_loss: 0.1241 - val_acc: 0.3732\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.1234 - acc: 0.3754 - val_loss: 0.1242 - val_acc: 0.3709\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.1230 - acc: 0.3767 - val_loss: 0.1221 - val_acc: 0.3799\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0968 - acc: 0.5077 - val_loss: 0.0812 - val_acc: 0.5851\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0761 - acc: 0.6121 - val_loss: 0.0723 - val_acc: 0.6320\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0714 - acc: 0.6365 - val_loss: 0.0705 - val_acc: 0.6421\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0695 - acc: 0.6466 - val_loss: 0.0690 - val_acc: 0.6494\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0686 - acc: 0.6509 - val_loss: 0.0681 - val_acc: 0.6539\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0678 - acc: 0.6554 - val_loss: 0.0673 - val_acc: 0.6579\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0672 - acc: 0.6583 - val_loss: 0.0671 - val_acc: 0.6585\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0668 - acc: 0.6605 - val_loss: 0.0668 - val_acc: 0.6610\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0663 - acc: 0.6631 - val_loss: 0.0663 - val_acc: 0.6627\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0660 - acc: 0.6641 - val_loss: 0.0659 - val_acc: 0.6645\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0657 - acc: 0.6661 - val_loss: 0.0660 - val_acc: 0.6640\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0655 - acc: 0.6670 - val_loss: 0.0662 - val_acc: 0.6623\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0655 - acc: 0.6669 - val_loss: 0.0657 - val_acc: 0.6655\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0649 - acc: 0.6697 - val_loss: 0.0658 - val_acc: 0.6649\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0647 - acc: 0.6709 - val_loss: 0.0655 - val_acc: 0.6657\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0646 - acc: 0.6708 - val_loss: 0.0651 - val_acc: 0.6689\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0643 - acc: 0.6728 - val_loss: 0.0649 - val_acc: 0.6694\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0640 - acc: 0.6742 - val_loss: 0.0648 - val_acc: 0.6707\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0639 - acc: 0.6748 - val_loss: 0.0650 - val_acc: 0.6689\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0636 - acc: 0.6760 - val_loss: 0.0648 - val_acc: 0.6707\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0635 - acc: 0.6763 - val_loss: 0.0646 - val_acc: 0.6706\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0635 - acc: 0.6763 - val_loss: 0.0642 - val_acc: 0.6719\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0634 - acc: 0.6763 - val_loss: 0.0645 - val_acc: 0.6703\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0562 - acc: 0.7119 - val_loss: 0.0510 - val_acc: 0.7394\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0492 - acc: 0.7480 - val_loss: 0.0488 - val_acc: 0.7501\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0477 - acc: 0.7558 - val_loss: 0.0478 - val_acc: 0.7549\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0469 - acc: 0.7594 - val_loss: 0.0473 - val_acc: 0.7580\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0464 - acc: 0.7622 - val_loss: 0.0472 - val_acc: 0.7583\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0461 - acc: 0.7634 - val_loss: 0.0470 - val_acc: 0.7588\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0455 - acc: 0.7667 - val_loss: 0.0467 - val_acc: 0.7604\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0453 - acc: 0.7679 - val_loss: 0.0465 - val_acc: 0.7609\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0451 - acc: 0.7690 - val_loss: 0.0464 - val_acc: 0.7620\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0448 - acc: 0.7701 - val_loss: 0.0460 - val_acc: 0.7642\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0446 - acc: 0.7710 - val_loss: 0.0461 - val_acc: 0.7632\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0444 - acc: 0.7723 - val_loss: 0.0461 - val_acc: 0.7632\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0443 - acc: 0.7725 - val_loss: 0.0460 - val_acc: 0.7649\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0440 - acc: 0.7738 - val_loss: 0.0460 - val_acc: 0.7641\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0431 - acc: 0.7783 - val_loss: 0.0372 - val_acc: 0.8077\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0294 - acc: 0.8480 - val_loss: 0.0300 - val_acc: 0.8451\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0272 - acc: 0.8600 - val_loss: 0.0293 - val_acc: 0.8496\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0265 - acc: 0.8640 - val_loss: 0.0289 - val_acc: 0.8515\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0256 - acc: 0.8682 - val_loss: 0.0213 - val_acc: 0.8890\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0138 - acc: 0.9272 - val_loss: 0.0128 - val_acc: 0.9335\n"
     ]
    }
   ],
   "source": [
    "model2_out=model2.fit(x_train, y_train, batch_size=100, epochs=50,verbose =1,validation_data = (x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_77 (Dense)             (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 150)               30150     \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 10)                1510      \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 228,860\n",
      "Trainable params: 228,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(200,input_dim=784))\n",
    "model3.add(Activation('tanh'))\n",
    "model3.add(Dense(200))\n",
    "model3.add(Activation('tanh'))\n",
    "model3.add(Dense(150))\n",
    "model3.add(Activation('relu'))\n",
    "\n",
    "model3.add(Dense(10))\n",
    "model3.add(Activation('softmax'))\n",
    "model3.compile(loss='mse',optimizer=SGD(lr=0.01),metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0894 - acc: 0.1872 - val_loss: 0.0844 - val_acc: 0.3105\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0784 - acc: 0.3983 - val_loss: 0.0718 - val_acc: 0.4642\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0668 - acc: 0.5148 - val_loss: 0.0612 - val_acc: 0.5742\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0567 - acc: 0.6331 - val_loss: 0.0513 - val_acc: 0.6920\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0473 - acc: 0.7200 - val_loss: 0.0426 - val_acc: 0.7510\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0399 - acc: 0.7650 - val_loss: 0.0362 - val_acc: 0.7882\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0345 - acc: 0.7983 - val_loss: 0.0316 - val_acc: 0.8213\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0305 - acc: 0.8245 - val_loss: 0.0281 - val_acc: 0.8428\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0274 - acc: 0.8415 - val_loss: 0.0256 - val_acc: 0.8540\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0251 - acc: 0.8523 - val_loss: 0.0236 - val_acc: 0.8644\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0233 - acc: 0.8606 - val_loss: 0.0220 - val_acc: 0.8726\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0218 - acc: 0.8691 - val_loss: 0.0210 - val_acc: 0.8750\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0206 - acc: 0.8748 - val_loss: 0.0200 - val_acc: 0.8791\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0196 - acc: 0.8815 - val_loss: 0.0191 - val_acc: 0.8841\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0187 - acc: 0.8864 - val_loss: 0.0184 - val_acc: 0.8871\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0179 - acc: 0.8899 - val_loss: 0.0179 - val_acc: 0.8888\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0173 - acc: 0.8934 - val_loss: 0.0174 - val_acc: 0.8914\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0167 - acc: 0.8970 - val_loss: 0.0168 - val_acc: 0.8977\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0162 - acc: 0.9003 - val_loss: 0.0165 - val_acc: 0.8971\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0157 - acc: 0.9028 - val_loss: 0.0161 - val_acc: 0.8991\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0152 - acc: 0.9061 - val_loss: 0.0159 - val_acc: 0.8984\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0148 - acc: 0.9082 - val_loss: 0.0156 - val_acc: 0.9016\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0144 - acc: 0.9114 - val_loss: 0.0153 - val_acc: 0.9009\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0141 - acc: 0.9130 - val_loss: 0.0152 - val_acc: 0.9049\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0138 - acc: 0.9143 - val_loss: 0.0148 - val_acc: 0.9056\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0135 - acc: 0.9167 - val_loss: 0.0147 - val_acc: 0.9058\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0132 - acc: 0.9178 - val_loss: 0.0146 - val_acc: 0.9064\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0130 - acc: 0.9197 - val_loss: 0.0144 - val_acc: 0.9086\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0127 - acc: 0.9219 - val_loss: 0.0142 - val_acc: 0.9076\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0125 - acc: 0.9230 - val_loss: 0.0140 - val_acc: 0.9097\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0123 - acc: 0.9243 - val_loss: 0.0140 - val_acc: 0.9102\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0121 - acc: 0.9256 - val_loss: 0.0137 - val_acc: 0.9116\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0118 - acc: 0.9269 - val_loss: 0.0136 - val_acc: 0.9132\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0117 - acc: 0.9283 - val_loss: 0.0135 - val_acc: 0.9116\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0115 - acc: 0.9293 - val_loss: 0.0134 - val_acc: 0.9134\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0113 - acc: 0.9299 - val_loss: 0.0133 - val_acc: 0.9143\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0111 - acc: 0.9313 - val_loss: 0.0132 - val_acc: 0.9141\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0110 - acc: 0.9323 - val_loss: 0.0131 - val_acc: 0.9145\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0108 - acc: 0.9330 - val_loss: 0.0130 - val_acc: 0.9149\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0107 - acc: 0.9338 - val_loss: 0.0130 - val_acc: 0.9151\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0106 - acc: 0.9346 - val_loss: 0.0128 - val_acc: 0.9170\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0104 - acc: 0.9360 - val_loss: 0.0128 - val_acc: 0.9171\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0103 - acc: 0.9365 - val_loss: 0.0127 - val_acc: 0.9178\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0102 - acc: 0.9374 - val_loss: 0.0127 - val_acc: 0.9179\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0101 - acc: 0.9382 - val_loss: 0.0126 - val_acc: 0.9192\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0099 - acc: 0.9387 - val_loss: 0.0126 - val_acc: 0.9195\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0098 - acc: 0.9397 - val_loss: 0.0125 - val_acc: 0.9185\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0098 - acc: 0.9401 - val_loss: 0.0124 - val_acc: 0.9196\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0096 - acc: 0.9409 - val_loss: 0.0124 - val_acc: 0.9204\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0096 - acc: 0.9413 - val_loss: 0.0124 - val_acc: 0.9205\n"
     ]
    }
   ],
   "source": [
    "model3_out=model3.fit(x_train, y_train, batch_size=100, epochs=50,verbose =1,validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_109 (Dense)            (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 150)               30150     \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 10)                1510      \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 228,860\n",
      "Trainable params: 228,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.0911 - acc: 0.0982 - val_loss: 0.0906 - val_acc: 0.0919\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0904 - acc: 0.1219 - val_loss: 0.0903 - val_acc: 0.1393\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0902 - acc: 0.1271 - val_loss: 0.0901 - val_acc: 0.1216\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0900 - acc: 0.1170 - val_loss: 0.0900 - val_acc: 0.1170\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0899 - acc: 0.1152 - val_loss: 0.0899 - val_acc: 0.1156\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0899 - acc: 0.1138 - val_loss: 0.0899 - val_acc: 0.1146\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0899 - acc: 0.1137 - val_loss: 0.0898 - val_acc: 0.1143\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0898 - acc: 0.1136 - val_loss: 0.0898 - val_acc: 0.1140\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0898 - acc: 0.1134 - val_loss: 0.0898 - val_acc: 0.1139\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0898 - acc: 0.1131 - val_loss: 0.0897 - val_acc: 0.1141\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0897 - acc: 0.1128 - val_loss: 0.0897 - val_acc: 0.1141\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0897 - acc: 0.1133 - val_loss: 0.0897 - val_acc: 0.1140\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0897 - acc: 0.1127 - val_loss: 0.0897 - val_acc: 0.1141\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0897 - acc: 0.1128 - val_loss: 0.0896 - val_acc: 0.1142\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0896 - acc: 0.1128 - val_loss: 0.0896 - val_acc: 0.1144\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0896 - acc: 0.1129 - val_loss: 0.0896 - val_acc: 0.1144\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0896 - acc: 0.1131 - val_loss: 0.0896 - val_acc: 0.1144\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0896 - acc: 0.1129 - val_loss: 0.0895 - val_acc: 0.1145\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0895 - acc: 0.1130 - val_loss: 0.0895 - val_acc: 0.1146\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0895 - acc: 0.1137 - val_loss: 0.0895 - val_acc: 0.1142\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0895 - acc: 0.1129 - val_loss: 0.0895 - val_acc: 0.1142\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0895 - acc: 0.1130 - val_loss: 0.0894 - val_acc: 0.1143\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0894 - acc: 0.1131 - val_loss: 0.0894 - val_acc: 0.1143\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0894 - acc: 0.1129 - val_loss: 0.0894 - val_acc: 0.1146\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0894 - acc: 0.1131 - val_loss: 0.0894 - val_acc: 0.1146\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0894 - acc: 0.1133 - val_loss: 0.0893 - val_acc: 0.1146\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0893 - acc: 0.1141 - val_loss: 0.0893 - val_acc: 0.1142\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0893 - acc: 0.1141 - val_loss: 0.0893 - val_acc: 0.1144\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0893 - acc: 0.1135 - val_loss: 0.0893 - val_acc: 0.1147\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0893 - acc: 0.1143 - val_loss: 0.0892 - val_acc: 0.1145\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0892 - acc: 0.1143 - val_loss: 0.0892 - val_acc: 0.1146\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0892 - acc: 0.1139 - val_loss: 0.0892 - val_acc: 0.1152\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0892 - acc: 0.1147 - val_loss: 0.0892 - val_acc: 0.1155\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0892 - acc: 0.1152 - val_loss: 0.0891 - val_acc: 0.1156\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0891 - acc: 0.1143 - val_loss: 0.0891 - val_acc: 0.1166\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0891 - acc: 0.1153 - val_loss: 0.0891 - val_acc: 0.1172\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0891 - acc: 0.1174 - val_loss: 0.0890 - val_acc: 0.1159\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0890 - acc: 0.1146 - val_loss: 0.0890 - val_acc: 0.1174\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0890 - acc: 0.1151 - val_loss: 0.0890 - val_acc: 0.1195\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0890 - acc: 0.1168 - val_loss: 0.0889 - val_acc: 0.1202\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0890 - acc: 0.1166 - val_loss: 0.0889 - val_acc: 0.1215\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0889 - acc: 0.1182 - val_loss: 0.0889 - val_acc: 0.1204\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0889 - acc: 0.1194 - val_loss: 0.0889 - val_acc: 0.1193\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0889 - acc: 0.1174 - val_loss: 0.0888 - val_acc: 0.1211\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0888 - acc: 0.1194 - val_loss: 0.0888 - val_acc: 0.1218\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0888 - acc: 0.1191 - val_loss: 0.0888 - val_acc: 0.1222\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0888 - acc: 0.1196 - val_loss: 0.0887 - val_acc: 0.1230\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0887 - acc: 0.1205 - val_loss: 0.0887 - val_acc: 0.1239\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0887 - acc: 0.1220 - val_loss: 0.0886 - val_acc: 0.1239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0887 - acc: 0.1222 - val_loss: 0.0886 - val_acc: 0.1248\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(200,input_dim=784))\n",
    "model4.add(Activation('hard_sigmoid'))\n",
    "model4.add(Dense(200))\n",
    "model4.add(Activation('hard_sigmoid'))\n",
    "model4.add(Dense(150))\n",
    "model4.add(Activation('hard_sigmoid'))\n",
    "\n",
    "model4.add(Dense(10))\n",
    "model4.add(Activation('softmax'))\n",
    "model4.compile(loss='mse',optimizer=SGD(lr=0.01),metrics=['accuracy'])\n",
    "model4.summary()\n",
    "model4_out=model4.fit(x_train, y_train, batch_size=100, epochs=50,verbose =1,validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_85 (Dense)             (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 150)               30150     \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 10)                1510      \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 228,860\n",
      "Trainable params: 228,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1173 - acc: 0.4002 - val_loss: 0.0947 - val_acc: 0.5180\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0912 - acc: 0.5360 - val_loss: 0.0890 - val_acc: 0.5464\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0855 - acc: 0.5647 - val_loss: 0.0770 - val_acc: 0.6063\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0735 - acc: 0.6253 - val_loss: 0.0707 - val_acc: 0.6400\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0706 - acc: 0.6405 - val_loss: 0.0686 - val_acc: 0.6518\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0696 - acc: 0.6467 - val_loss: 0.0688 - val_acc: 0.6502\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0687 - acc: 0.6516 - val_loss: 0.0695 - val_acc: 0.6478\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0682 - acc: 0.6543 - val_loss: 0.0674 - val_acc: 0.6577\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0679 - acc: 0.6555 - val_loss: 0.0668 - val_acc: 0.6608\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0674 - acc: 0.6587 - val_loss: 0.0671 - val_acc: 0.6603\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0669 - acc: 0.6612 - val_loss: 0.0684 - val_acc: 0.6532\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0667 - acc: 0.6616 - val_loss: 0.0671 - val_acc: 0.6596\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0661 - acc: 0.6642 - val_loss: 0.0659 - val_acc: 0.6664\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0658 - acc: 0.6659 - val_loss: 0.0660 - val_acc: 0.6654\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0655 - acc: 0.6674 - val_loss: 0.0652 - val_acc: 0.6691\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0654 - acc: 0.6687 - val_loss: 0.0660 - val_acc: 0.6662\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0654 - acc: 0.6682 - val_loss: 0.0658 - val_acc: 0.6656\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0649 - acc: 0.6705 - val_loss: 0.0655 - val_acc: 0.6678\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0648 - acc: 0.6711 - val_loss: 0.0650 - val_acc: 0.6693\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0647 - acc: 0.6714 - val_loss: 0.0650 - val_acc: 0.6697\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0647 - acc: 0.6721 - val_loss: 0.0650 - val_acc: 0.6701\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0645 - acc: 0.6726 - val_loss: 0.0648 - val_acc: 0.6717\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0643 - acc: 0.6736 - val_loss: 0.0649 - val_acc: 0.6701\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0642 - acc: 0.6745 - val_loss: 0.0658 - val_acc: 0.6653\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0644 - acc: 0.6724 - val_loss: 0.0649 - val_acc: 0.6706\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0639 - acc: 0.6751 - val_loss: 0.0644 - val_acc: 0.6725\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0638 - acc: 0.6758 - val_loss: 0.0646 - val_acc: 0.6713\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0637 - acc: 0.6766 - val_loss: 0.0644 - val_acc: 0.6724\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0636 - acc: 0.6769 - val_loss: 0.0641 - val_acc: 0.6740\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0637 - acc: 0.6769 - val_loss: 0.0649 - val_acc: 0.6702\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0633 - acc: 0.6785 - val_loss: 0.0650 - val_acc: 0.6701\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0633 - acc: 0.6786 - val_loss: 0.0645 - val_acc: 0.6723\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0633 - acc: 0.6781 - val_loss: 0.0646 - val_acc: 0.6712\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0631 - acc: 0.6795 - val_loss: 0.0644 - val_acc: 0.6731\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0634 - acc: 0.6787 - val_loss: 0.0641 - val_acc: 0.6746\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0632 - acc: 0.6796 - val_loss: 0.0638 - val_acc: 0.6760\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0629 - acc: 0.6803 - val_loss: 0.0641 - val_acc: 0.6741\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0627 - acc: 0.6814 - val_loss: 0.0637 - val_acc: 0.6759\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0628 - acc: 0.6813 - val_loss: 0.0644 - val_acc: 0.6727\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0628 - acc: 0.6814 - val_loss: 0.0648 - val_acc: 0.6716\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0629 - acc: 0.6804 - val_loss: 0.0650 - val_acc: 0.6698\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0628 - acc: 0.6809 - val_loss: 0.0644 - val_acc: 0.6729\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0628 - acc: 0.6812 - val_loss: 0.0641 - val_acc: 0.6743\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0624 - acc: 0.6829 - val_loss: 0.0643 - val_acc: 0.6731\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0626 - acc: 0.6819 - val_loss: 0.0643 - val_acc: 0.6734\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0624 - acc: 0.6831 - val_loss: 0.0636 - val_acc: 0.6762\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0626 - acc: 0.6823 - val_loss: 0.0639 - val_acc: 0.6751\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0627 - acc: 0.6813 - val_loss: 0.0634 - val_acc: 0.6770\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0623 - acc: 0.6837 - val_loss: 0.0634 - val_acc: 0.6778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0623 - acc: 0.6834 - val_loss: 0.0639 - val_acc: 0.6754\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Dense(200,input_dim=784))\n",
    "model5.add(Activation('softplus'))\n",
    "model5.add(Dense(200))\n",
    "model5.add(Activation('softplus'))\n",
    "model5.add(Dense(150))\n",
    "model5.add(Activation('softplus'))\n",
    "\n",
    "model5.add(Dense(10))\n",
    "model5.add(Activation('softmax'))\n",
    "model5.compile(loss='mse',optimizer=SGD(lr=0.01),metrics=['accuracy'])\n",
    "model5.summary()\n",
    "model5_out=model5.fit(x_train, y_train, batch_size=100, epochs=50,verbose =1,validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_89 (Dense)             (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 150)               30150     \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 10)                1510      \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 228,860\n",
      "Trainable params: 228,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1364 - acc: 0.3085 - val_loss: 0.1152 - val_acc: 0.4159\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1046 - acc: 0.4688 - val_loss: 0.0938 - val_acc: 0.5237\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0921 - acc: 0.5328 - val_loss: 0.0907 - val_acc: 0.5401\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0899 - acc: 0.5444 - val_loss: 0.0892 - val_acc: 0.5477\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0891 - acc: 0.5486 - val_loss: 0.0883 - val_acc: 0.5519\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0879 - acc: 0.5544 - val_loss: 0.0880 - val_acc: 0.5548\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0872 - acc: 0.5581 - val_loss: 0.0872 - val_acc: 0.5571\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0815 - acc: 0.5860 - val_loss: 0.0756 - val_acc: 0.6158\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0725 - acc: 0.6313 - val_loss: 0.0626 - val_acc: 0.6814\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0595 - acc: 0.6964 - val_loss: 0.0571 - val_acc: 0.7094\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0565 - acc: 0.7122 - val_loss: 0.0559 - val_acc: 0.7153\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0551 - acc: 0.7199 - val_loss: 0.0541 - val_acc: 0.7243\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0540 - acc: 0.7252 - val_loss: 0.0545 - val_acc: 0.7230\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0531 - acc: 0.7291 - val_loss: 0.0536 - val_acc: 0.7259\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0527 - acc: 0.7318 - val_loss: 0.0530 - val_acc: 0.7294\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0518 - acc: 0.7359 - val_loss: 0.0534 - val_acc: 0.7275\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0514 - acc: 0.7376 - val_loss: 0.0527 - val_acc: 0.7308\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0510 - acc: 0.7398 - val_loss: 0.0515 - val_acc: 0.7375\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0506 - acc: 0.7415 - val_loss: 0.0521 - val_acc: 0.7356\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0505 - acc: 0.7423 - val_loss: 0.0511 - val_acc: 0.7390\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0499 - acc: 0.7451 - val_loss: 0.0514 - val_acc: 0.7383\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0494 - acc: 0.7473 - val_loss: 0.0507 - val_acc: 0.7402\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0493 - acc: 0.7478 - val_loss: 0.0502 - val_acc: 0.7423\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0492 - acc: 0.7483 - val_loss: 0.0508 - val_acc: 0.7415\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0488 - acc: 0.7510 - val_loss: 0.0501 - val_acc: 0.7439\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0487 - acc: 0.7502 - val_loss: 0.0499 - val_acc: 0.7433\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0484 - acc: 0.7517 - val_loss: 0.0500 - val_acc: 0.7428\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0483 - acc: 0.7515 - val_loss: 0.0493 - val_acc: 0.7466\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0477 - acc: 0.7546 - val_loss: 0.0504 - val_acc: 0.7401\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0479 - acc: 0.7534 - val_loss: 0.0494 - val_acc: 0.7457\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0475 - acc: 0.7555 - val_loss: 0.0493 - val_acc: 0.7459\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0472 - acc: 0.7569 - val_loss: 0.0492 - val_acc: 0.7468\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0471 - acc: 0.7571 - val_loss: 0.0488 - val_acc: 0.7485\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0468 - acc: 0.7582 - val_loss: 0.0483 - val_acc: 0.7501\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0466 - acc: 0.7595 - val_loss: 0.0490 - val_acc: 0.7468\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0463 - acc: 0.7598 - val_loss: 0.0482 - val_acc: 0.7490\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0462 - acc: 0.7596 - val_loss: 0.0485 - val_acc: 0.7466\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0462 - acc: 0.7597 - val_loss: 0.0484 - val_acc: 0.7477\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0459 - acc: 0.7613 - val_loss: 0.0488 - val_acc: 0.7465\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0455 - acc: 0.7623 - val_loss: 0.0482 - val_acc: 0.7497\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0457 - acc: 0.7620 - val_loss: 0.0479 - val_acc: 0.7503\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0453 - acc: 0.7629 - val_loss: 0.0477 - val_acc: 0.7517\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0450 - acc: 0.7639 - val_loss: 0.0475 - val_acc: 0.7512\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0447 - acc: 0.7649 - val_loss: 0.0481 - val_acc: 0.7473\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0448 - acc: 0.7646 - val_loss: 0.0471 - val_acc: 0.7513\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0444 - acc: 0.7662 - val_loss: 0.0474 - val_acc: 0.7500\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0441 - acc: 0.7662 - val_loss: 0.0476 - val_acc: 0.7482\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0439 - acc: 0.7673 - val_loss: 0.0468 - val_acc: 0.7524\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0438 - acc: 0.7680 - val_loss: 0.0469 - val_acc: 0.7516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0437 - acc: 0.7675 - val_loss: 0.0463 - val_acc: 0.7531\n"
     ]
    }
   ],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(Dense(200,input_dim=784))\n",
    "model6.add(Activation('selu'))\n",
    "model6.add(Dense(200))\n",
    "model6.add(Activation('selu'))\n",
    "model6.add(Dense(150))\n",
    "model6.add(Activation('selu'))\n",
    "\n",
    "model6.add(Dense(10))\n",
    "model6.add(Activation('softmax'))\n",
    "model6.compile(loss='mse',optimizer=SGD(lr=0.01),metrics=['accuracy'])\n",
    "model6.summary()\n",
    "model6_out=model6.fit(x_train, y_train, batch_size=100, epochs=50,verbose =1,validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_93 (Dense)             (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 150)               30150     \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 10)                1510      \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 228,860\n",
      "Trainable params: 228,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1199 - acc: 0.3895 - val_loss: 0.1078 - val_acc: 0.4517\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.1061 - acc: 0.4611 - val_loss: 0.1059 - val_acc: 0.4636\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.1044 - acc: 0.4705 - val_loss: 0.1036 - val_acc: 0.4746\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.1034 - acc: 0.4755 - val_loss: 0.1030 - val_acc: 0.4771\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.1027 - acc: 0.4791 - val_loss: 0.1025 - val_acc: 0.4793\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0980 - acc: 0.5020 - val_loss: 0.0901 - val_acc: 0.5415\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0888 - acc: 0.5478 - val_loss: 0.0870 - val_acc: 0.5571\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0865 - acc: 0.5597 - val_loss: 0.0861 - val_acc: 0.5616\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0855 - acc: 0.5647 - val_loss: 0.0857 - val_acc: 0.5642\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0852 - acc: 0.5662 - val_loss: 0.0856 - val_acc: 0.5631\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0844 - acc: 0.5700 - val_loss: 0.0848 - val_acc: 0.5676\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0828 - acc: 0.5775 - val_loss: 0.0759 - val_acc: 0.6114\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0716 - acc: 0.6331 - val_loss: 0.0694 - val_acc: 0.6441\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0645 - acc: 0.6687 - val_loss: 0.0543 - val_acc: 0.7216\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0518 - acc: 0.7339 - val_loss: 0.0511 - val_acc: 0.7373\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0496 - acc: 0.7452 - val_loss: 0.0500 - val_acc: 0.7436\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0487 - acc: 0.7498 - val_loss: 0.0496 - val_acc: 0.7458\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0481 - acc: 0.7526 - val_loss: 0.0507 - val_acc: 0.7387\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0474 - acc: 0.7563 - val_loss: 0.0481 - val_acc: 0.7523\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0468 - acc: 0.7594 - val_loss: 0.0476 - val_acc: 0.7551\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0365 - acc: 0.8118 - val_loss: 0.0319 - val_acc: 0.8366\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0301 - acc: 0.8457 - val_loss: 0.0305 - val_acc: 0.8437\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0292 - acc: 0.8503 - val_loss: 0.0298 - val_acc: 0.8472\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0285 - acc: 0.8531 - val_loss: 0.0297 - val_acc: 0.8466\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0281 - acc: 0.8554 - val_loss: 0.0298 - val_acc: 0.8473\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0276 - acc: 0.8577 - val_loss: 0.0288 - val_acc: 0.8511\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0274 - acc: 0.8591 - val_loss: 0.0289 - val_acc: 0.8517\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0270 - acc: 0.8607 - val_loss: 0.0284 - val_acc: 0.8545\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0268 - acc: 0.8618 - val_loss: 0.0281 - val_acc: 0.8547\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0262 - acc: 0.8648 - val_loss: 0.0281 - val_acc: 0.8551\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0261 - acc: 0.8650 - val_loss: 0.0276 - val_acc: 0.8569\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0260 - acc: 0.8661 - val_loss: 0.0280 - val_acc: 0.8557\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0258 - acc: 0.8671 - val_loss: 0.0279 - val_acc: 0.8568\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0256 - acc: 0.8676 - val_loss: 0.0273 - val_acc: 0.8584\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0254 - acc: 0.8690 - val_loss: 0.0277 - val_acc: 0.8570\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0254 - acc: 0.8689 - val_loss: 0.0272 - val_acc: 0.8592\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0250 - acc: 0.8708 - val_loss: 0.0274 - val_acc: 0.8577\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0249 - acc: 0.8714 - val_loss: 0.0272 - val_acc: 0.8589\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0247 - acc: 0.8723 - val_loss: 0.0270 - val_acc: 0.8605\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0246 - acc: 0.8731 - val_loss: 0.0268 - val_acc: 0.8613\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0245 - acc: 0.8731 - val_loss: 0.0272 - val_acc: 0.8594\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0243 - acc: 0.8741 - val_loss: 0.0265 - val_acc: 0.8625\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0242 - acc: 0.8747 - val_loss: 0.0270 - val_acc: 0.8605\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0241 - acc: 0.8755 - val_loss: 0.0264 - val_acc: 0.8630\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0239 - acc: 0.8760 - val_loss: 0.0265 - val_acc: 0.8625\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0239 - acc: 0.8762 - val_loss: 0.0266 - val_acc: 0.8621\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0237 - acc: 0.8774 - val_loss: 0.0262 - val_acc: 0.8640\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0236 - acc: 0.8774 - val_loss: 0.0264 - val_acc: 0.8631\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0235 - acc: 0.8785 - val_loss: 0.0268 - val_acc: 0.8610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0235 - acc: 0.8783 - val_loss: 0.0260 - val_acc: 0.8657\n"
     ]
    }
   ],
   "source": [
    "model7 = Sequential()\n",
    "model7.add(Dense(200,input_dim=784))\n",
    "model7.add(Activation('elu'))\n",
    "model7.add(Dense(200))\n",
    "model7.add(Activation('elu'))\n",
    "model7.add(Dense(150))\n",
    "model7.add(Activation('elu'))\n",
    "\n",
    "model7.add(Dense(10))\n",
    "model7.add(Activation('softmax'))\n",
    "model7.compile(loss='mse',optimizer=SGD(lr=0.01),metrics=['accuracy'])\n",
    "model7.summary()\n",
    "model7_out=model7.fit(x_train, y_train, batch_size=100, epochs=50,verbose =1,validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epoch')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_out.history[\"acc\"])\n",
    "plt.plot(model2_out.history[\"acc\"])\n",
    "plt.plot(model3_out.history[\"acc\"])\n",
    "plt.plot(model4_out.history[\"acc\"])\n",
    "plt.plot(model5_out.history[\"acc\"])\n",
    "plt.plot(model6_out.history[\"acc\"])\n",
    "plt.plot(model7_out.history[\"acc\"])\n",
    "plt.title(\"model training accuracy\")\n",
    "plt.legend([\"sigmoid\",\"Relu\",\"tanh\",\"hard_sigmoid\",\"softplus\",\"selu\",\"elu\"],loc=\"best\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 運不同的accuracy function 其他參數不變的情況下，可以看出不同的方程有不同的趨勢從圖中顯示tenh是快超過百分之九十的，但sigmoid and hard_sigmod 比較低，我決定改變learning rate 來試試看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_121 (Dense)            (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 150)               30150     \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 10)                1510      \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 228,860\n",
      "Trainable params: 228,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0905 - acc: 0.1304 - val_loss: 0.0895 - val_acc: 0.1165\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0893 - acc: 0.1388 - val_loss: 0.0891 - val_acc: 0.1945\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0889 - acc: 0.1743 - val_loss: 0.0886 - val_acc: 0.2056\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0884 - acc: 0.2084 - val_loss: 0.0881 - val_acc: 0.2367\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0877 - acc: 0.2324 - val_loss: 0.0873 - val_acc: 0.2431\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0869 - acc: 0.2452 - val_loss: 0.0863 - val_acc: 0.2595\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0857 - acc: 0.2575 - val_loss: 0.0848 - val_acc: 0.2597\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0839 - acc: 0.2662 - val_loss: 0.0826 - val_acc: 0.2603\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0814 - acc: 0.2876 - val_loss: 0.0799 - val_acc: 0.3247\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0787 - acc: 0.3559 - val_loss: 0.0773 - val_acc: 0.3847\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0762 - acc: 0.4122 - val_loss: 0.0748 - val_acc: 0.4220\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0736 - acc: 0.4410 - val_loss: 0.0720 - val_acc: 0.4482\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0706 - acc: 0.4636 - val_loss: 0.0687 - val_acc: 0.4699\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0670 - acc: 0.4844 - val_loss: 0.0650 - val_acc: 0.5029\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0631 - acc: 0.5205 - val_loss: 0.0610 - val_acc: 0.5470\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0590 - acc: 0.5722 - val_loss: 0.0570 - val_acc: 0.6072\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0550 - acc: 0.6238 - val_loss: 0.0530 - val_acc: 0.6555\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0512 - acc: 0.6687 - val_loss: 0.0493 - val_acc: 0.7060\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0475 - acc: 0.7182 - val_loss: 0.0457 - val_acc: 0.7404\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0439 - acc: 0.7557 - val_loss: 0.0421 - val_acc: 0.7750\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0404 - acc: 0.7830 - val_loss: 0.0386 - val_acc: 0.7914\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0368 - acc: 0.8037 - val_loss: 0.0350 - val_acc: 0.8191\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0334 - acc: 0.8286 - val_loss: 0.0317 - val_acc: 0.8343\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0302 - acc: 0.8490 - val_loss: 0.0286 - val_acc: 0.8578\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0273 - acc: 0.8666 - val_loss: 0.0259 - val_acc: 0.8724\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0249 - acc: 0.8787 - val_loss: 0.0237 - val_acc: 0.8807\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0228 - acc: 0.8873 - val_loss: 0.0219 - val_acc: 0.8874\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0211 - acc: 0.8927 - val_loss: 0.0204 - val_acc: 0.8915\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0197 - acc: 0.8970 - val_loss: 0.0190 - val_acc: 0.8987\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0185 - acc: 0.9026 - val_loss: 0.0180 - val_acc: 0.8994\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0175 - acc: 0.9057 - val_loss: 0.0171 - val_acc: 0.9046\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0166 - acc: 0.9096 - val_loss: 0.0164 - val_acc: 0.9068\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0158 - acc: 0.9121 - val_loss: 0.0158 - val_acc: 0.9092\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0152 - acc: 0.9153 - val_loss: 0.0152 - val_acc: 0.9125\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0146 - acc: 0.9179 - val_loss: 0.0147 - val_acc: 0.9128\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0140 - acc: 0.9196 - val_loss: 0.0142 - val_acc: 0.9159\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0136 - acc: 0.9226 - val_loss: 0.0139 - val_acc: 0.9163\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0131 - acc: 0.9245 - val_loss: 0.0135 - val_acc: 0.9155\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0127 - acc: 0.9265 - val_loss: 0.0132 - val_acc: 0.9179\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0124 - acc: 0.9290 - val_loss: 0.0129 - val_acc: 0.9204\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0120 - acc: 0.9310 - val_loss: 0.0127 - val_acc: 0.9227\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0117 - acc: 0.9322 - val_loss: 0.0125 - val_acc: 0.9243\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0114 - acc: 0.9344 - val_loss: 0.0122 - val_acc: 0.9249\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0111 - acc: 0.9354 - val_loss: 0.0120 - val_acc: 0.9259\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0109 - acc: 0.9365 - val_loss: 0.0118 - val_acc: 0.9248\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0106 - acc: 0.9380 - val_loss: 0.0117 - val_acc: 0.9260\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0104 - acc: 0.9395 - val_loss: 0.0115 - val_acc: 0.9290\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0102 - acc: 0.9408 - val_loss: 0.0113 - val_acc: 0.9291\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0100 - acc: 0.9420 - val_loss: 0.0111 - val_acc: 0.9298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0098 - acc: 0.9433 - val_loss: 0.0111 - val_acc: 0.9289\n"
     ]
    }
   ],
   "source": [
    "model9 = Sequential()\n",
    "model9.add(Dense(200,input_dim=784))\n",
    "model9.add(Activation('sigmoid'))\n",
    "model9.add(Dense(200))\n",
    "model9.add(Activation('sigmoid'))\n",
    "model9.add(Dense(150))\n",
    "model9.add(Activation('sigmoid'))\n",
    "\n",
    "model9.add(Dense(10))\n",
    "model9.add(Activation('softmax'))\n",
    "model9.compile(loss='mse',optimizer=SGD(lr=0.1),metrics=['accuracy'])\n",
    "model9.summary()\n",
    "model9_out=model9.fit(x_train, y_train, batch_size=100, epochs=50,verbose =1,validation_data = (x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_117 (Dense)            (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 150)               30150     \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 10)                1510      \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 228,860\n",
      "Trainable params: 228,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0902 - acc: 0.1507 - val_loss: 0.0896 - val_acc: 0.1482\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0895 - acc: 0.1504 - val_loss: 0.0893 - val_acc: 0.1734\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0891 - acc: 0.1595 - val_loss: 0.0889 - val_acc: 0.1860\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0888 - acc: 0.1742 - val_loss: 0.0885 - val_acc: 0.2001\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0883 - acc: 0.1921 - val_loss: 0.0881 - val_acc: 0.1817\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0878 - acc: 0.1980 - val_loss: 0.0875 - val_acc: 0.2461\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0871 - acc: 0.2185 - val_loss: 0.0866 - val_acc: 0.2419\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0862 - acc: 0.2428 - val_loss: 0.0855 - val_acc: 0.2611\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0848 - acc: 0.2800 - val_loss: 0.0838 - val_acc: 0.3049\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0829 - acc: 0.3239 - val_loss: 0.0816 - val_acc: 0.3477\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0807 - acc: 0.3607 - val_loss: 0.0794 - val_acc: 0.3759\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0787 - acc: 0.4042 - val_loss: 0.0776 - val_acc: 0.4243\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0769 - acc: 0.4426 - val_loss: 0.0759 - val_acc: 0.4442\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0752 - acc: 0.4571 - val_loss: 0.0741 - val_acc: 0.4666\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0733 - acc: 0.4677 - val_loss: 0.0721 - val_acc: 0.4671\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0711 - acc: 0.4723 - val_loss: 0.0697 - val_acc: 0.4730\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0686 - acc: 0.4805 - val_loss: 0.0670 - val_acc: 0.4866\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0657 - acc: 0.5069 - val_loss: 0.0640 - val_acc: 0.5143\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0625 - acc: 0.5409 - val_loss: 0.0607 - val_acc: 0.5567\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0590 - acc: 0.5716 - val_loss: 0.0572 - val_acc: 0.5823\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0554 - acc: 0.6005 - val_loss: 0.0536 - val_acc: 0.6142\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0519 - acc: 0.6353 - val_loss: 0.0501 - val_acc: 0.6491\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0485 - acc: 0.6685 - val_loss: 0.0468 - val_acc: 0.6840\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0452 - acc: 0.7041 - val_loss: 0.0436 - val_acc: 0.7171\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0420 - acc: 0.7381 - val_loss: 0.0403 - val_acc: 0.7610\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0389 - acc: 0.7739 - val_loss: 0.0372 - val_acc: 0.7958\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0359 - acc: 0.8075 - val_loss: 0.0342 - val_acc: 0.8191\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0330 - acc: 0.8310 - val_loss: 0.0314 - val_acc: 0.8495\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0303 - acc: 0.8496 - val_loss: 0.0289 - val_acc: 0.8583\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0279 - acc: 0.8616 - val_loss: 0.0267 - val_acc: 0.8671\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0258 - acc: 0.8708 - val_loss: 0.0248 - val_acc: 0.8727\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0240 - acc: 0.8777 - val_loss: 0.0231 - val_acc: 0.8813\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0224 - acc: 0.8828 - val_loss: 0.0217 - val_acc: 0.8849\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0211 - acc: 0.8881 - val_loss: 0.0205 - val_acc: 0.8887\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0199 - acc: 0.8925 - val_loss: 0.0195 - val_acc: 0.8908\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0189 - acc: 0.8952 - val_loss: 0.0185 - val_acc: 0.8945\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0180 - acc: 0.8979 - val_loss: 0.0177 - val_acc: 0.8987\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0173 - acc: 0.9007 - val_loss: 0.0171 - val_acc: 0.9002\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0167 - acc: 0.9033 - val_loss: 0.0166 - val_acc: 0.9017\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0161 - acc: 0.9073 - val_loss: 0.0161 - val_acc: 0.9055\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0155 - acc: 0.9090 - val_loss: 0.0156 - val_acc: 0.9064\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0151 - acc: 0.9112 - val_loss: 0.0152 - val_acc: 0.9076\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0146 - acc: 0.9139 - val_loss: 0.0148 - val_acc: 0.9102\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0142 - acc: 0.9159 - val_loss: 0.0146 - val_acc: 0.9123\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0139 - acc: 0.9170 - val_loss: 0.0143 - val_acc: 0.9121\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0135 - acc: 0.9195 - val_loss: 0.0140 - val_acc: 0.9136\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0132 - acc: 0.9215 - val_loss: 0.0136 - val_acc: 0.9148\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0129 - acc: 0.9236 - val_loss: 0.0134 - val_acc: 0.9162\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0126 - acc: 0.9249 - val_loss: 0.0132 - val_acc: 0.9189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0123 - acc: 0.9269 - val_loss: 0.0130 - val_acc: 0.9196\n"
     ]
    }
   ],
   "source": [
    "model8 = Sequential()\n",
    "model8.add(Dense(200,input_dim=784))\n",
    "model8.add(Activation('hard_sigmoid'))\n",
    "model8.add(Dense(200))\n",
    "model8.add(Activation('hard_sigmoid'))\n",
    "model8.add(Dense(150))\n",
    "model8.add(Activation('hard_sigmoid'))\n",
    "\n",
    "model8.add(Dense(10))\n",
    "model8.add(Activation('softmax'))\n",
    "model8.compile(loss='mse',optimizer=SGD(lr=0.1),metrics=['accuracy'])\n",
    "model8.summary()\n",
    "model8_out=model8.fit(x_train, y_train, batch_size=100, epochs=50,verbose =1,validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epoch')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xd8FHX6wPHPk5CeAIGEGnoRUHoEFRBUVFQsqKgontg473f2cqBnOz3reed5dmxgAxEQQVBs2AuEIr2EHkInJCGkbp7fH7PEJQQImNnNbp7367Wv3Zn57swzKfPMfL8z36+oKsYYYwxAWKADMMYYU31YUjDGGFPGkoIxxpgylhSMMcaUsaRgjDGmjCUFY4wxZSwpmGpBRMaKyD8rWXa9iAx0MZarROTzqi5rTDCwpGBCytEkl0NR1fdU9ayqLmtMMLCkYGoUEakV6BiCgTjs+FAD2S/dVJq32uYeEVkkInki8oaINBSRT0UkV0S+FJFEn/IXiMhSEdkjIt+ISEefZd1FZL73ex8A0eW2NVhEFnq/+5OIdKlEfCOBq4C/icheEZnuE/coEVkE5IlILREZLSJrvNtfJiJDfNYzQkR+8JlWEblJRFaLSJaIvCgicgxlw0Xk3yKyU0TWicjN3vIVJqrDxehdfqOILPdZ3sM7v5mITBGRHSKyS0Re8M5/WETe9fl+S9/te39Hj4nIj8A+oLWIXOuzjbUi8udyMVzo/T3leGMdJCJDRWReuXJ3icjUI/0OTTWgqvayV6VewHrgF6Ah0BTYDswHugNRwNfAQ96y7YE84EwgAvgbkA5Eel8bgDu8yy4FioF/er/bw7vu3kA4cI1321E+cQw8RIxj96+nXNwLgWZAjHfeUKAJzonR5d5YG3uXjQB+8Pm+Ap8AdYHmwA5g0DGUvQlYBqQAicCX3vK1DrEvh4txKLAZOBEQoC3Qwvvz+g14FojDSbZ9vd95GHjXZ/0tfbcPfANsBI4Hanl/N+cBbbzb6I+TLHp4y/cCsr2/4zCcv4kO3r+F3UBHn20tAC4J9N+wvY78sisFc7SeV9VtqroZ+B74VVUXqGoh8BFOggDnIDZDVb9Q1WLgGSAGOAU4CeeA819VLVbVScBcn23cCLyqqr+qqkdVxwGF3u8dq/+p6iZVzQdQ1Q9VNVNVS1X1A2A1zkHuUJ5U1T2quhGYDXQ7hrKXAc+paoaqZgFPHi7gI8R4A/C0qs5VR7qqbvAubwLco6p5qlqgqj8cYhMVGauqS1W1xPu7maGqa7zb+Bb4HOjnLXs98Kb3d1yqqptVdYX3b+EDYDiAiByPk4A+OYo4TIBYUjBHa5vP5/wKpuO9n5vgXA0AoKqlwCacs8kmwGZV9e2NcYPP5xbAXd6qoz0isgfnLL/JH4h7k++EiPzJp3pqD3ACkHSY72/1+byP3/fzaMo2KRfHATGVd4QYmwFrKvhaM2CDqpYcbt2HUf7ndI6I/CIiu70xnFuJGADGAVd6q86uBiZ6k4Wp5iwpGLdk4hzcAafhEucgshnYAjTdX9fu1dzn8ybgMVWt6/OKVdXxldjuobr9LZsvIi2A14CbgfqqWhdYglNF4qYtOFVH+zU7VMFKxLgJp1qnvE1A80O0U+QBsT7TjSoo4/tzigIm41zlNfTGMLMSMaCqvwBFOFcVVwLvVFTOVD+WFIxbJgLnicgZIhIB3IVTBfQT8DNQAtzqbfS9mAOrbl4DbhKR3uKIE5HzRCShEtvdBrQ+Qpk4nIPfDgARuRbnLNxtE4HbRKSpiNQFRh2m7JFifB24W0R6en9Gbb2JZA5O8nnS+3OLFpE+3u8sBE4VkeYiUge49wjxRuK0D+wASkTkHMD39ts3gGu9v+Mw73518Fn+NvACUHKUVVgmgCwpGFeo6kqcOuXngZ3A+cD5qlqkqkXAxTiNtFk47Q9TfL6bhtOu8IJ3ebq3bGW8AXTyVrlUeLeLqi4D/o2TnLYBnYEfj24Pj8lrOHXyi3AaXmfiJEfP0caoqh8CjwHvA7nAVKCeqnpwftZtcRqNM3B+vqjqFzh1/YuAeRyhjl9Vc4FbcZJZFs4Z/zSf5XOAa3EatbOBb/G5OsS5OjgBu0oIKnJgta4xxl+8Z96vqGqLIxYOQiISg3MXWQ9VXR3oeEzl2JWCMX4iIjEicq63yqwp8BDOHVuh6i/AXEsIwcWuFIzxExGJxali6YBzp9YM4DZVzQloYC4QkfU4DdIXqeqCAIdjjoIlBWOMMWWs+sgYY0yZoOscLCkpSVu2bBnoMIwxJqjMmzdvp6omH6lc0CWFli1bkpaWFugwjDEmqIjIhiOXsuojY4wxPiwpGGOMKWNJwRhjTJmga1OoSHFxMRkZGRQUFAQ6FOMjOjqalJQUIiIiAh2KMaaSQiIpZGRkkJCQQMuWLTmw400TKKrKrl27yMjIoFWrVoEOxxhTSSFRfVRQUED9+vUtIVQjIkL9+vXt6s2YIBMSSQGwhFAN2e/EmOATEtVHxhgTrDylyt7CEvYVlZBXWMLeQg/7Cku88zxly/YWejijQwO6NqvrajyWFFx0ww03cOedd9KpUyfXtnHuuefy/vvvU7fugX8oDz/8MPHx8dx9992ubduYmkpVKSwpJaegmNyCEu+r+ID3HO/nvMIS8go95HkP+r6f9xaWUFBcWuntNkiIsqQQzF5//XXXtzFz5kzXt2FMqCgo9rArr4iduYXs3FtIdn4x+cUe8os8FBR7KCguJb/Yw74iD/lFzpl6frGHvMLfP+8/8Bd7jtyZaHxULeKiwomLqkV8VC1iI8NpUjeauKhaxEbWIt5nWZx3+f7PcZG/fzcuqhaxEeGEhblfJWtJoYrk5eVx2WWXkZGRgcfj4YEHHuDll1/mmWeeITU1lTfeeIOnnnqKJk2a0K5dO6KionjhhRcYMWIEMTExrFixgg0bNvDWW28xbtw4fv75Z3r37s3YsWMBGD9+PI8//jiqynnnncdTTz0F/N7tR1JSEo899hhvv/02zZo1Izk5mZ49ewbwJ2KMOwqKPWTtK2J3XhFZecXs3ldEVl4RWfuK2FtQQp73gJ5X5PFWyXjIzi9mZ24huYUlh113mEBMRDgxkeHERjoH6ZjIcOIia1E/PorYyHASomuREB1R9l47ulbZ5/ioAz+H++EgXtVCLin8Y/pSlmVWbff0nZrU5qHzjz9smc8++4wmTZowY8YMALKzs3n55ZcByMzM5NFHH2X+/PkkJCRw+umn07Vr17LvZmVl8fXXXzNt2jTOP/98fvzxR15//XVOPPFEFi5cSIMGDRg1ahTz5s0jMTGRs846i6lTp3LRRReVrWPevHlMmDCBBQsWUFJSQo8ePSwpmKCgquQXe9i11zmw78pzDvK79haxPbeA7bmFbM8pLPucW3DoA3us92AeFxVOTIRzlp0QXYuUxBiS4qNIToiiflwkSfFRJCVEUTcmgtjIcKIinPIR4RLYGyRUoSgP9u3yvnb7fN4Jx50HKe7+X4dcUgiUzp07c/fddzNq1CgGDx5Mv379ypbNmTOH/v37U69ePQCGDh3KqlWrypaff/75iAidO3emYcOGdO7cGYDjjz+e9evXs2HDBgYMGEBystPB4VVXXcV33313QFL4/vvvGTJkCLGxsQBccMEFru+zMYeiquzOK2Lznnw2Z+WzeU8+O/cWkZ1fxJ59xWTtc96z853Ph6pXj6oVRoPaUTRIiKZ9wwT6tk0iOSGKenFR1IuLIDE2knpxkSTGRVI3JoJa4dXkhkpPsc8Bfafznrfz9wN83k7Iz4LCXCja67wX7oWiXNBDtDFIONRJsaRwtI50Ru+W9u3bM2/ePGbOnMm9997LWWedVbbsSAMZRUVFARAWFlb2ef90SUkJtWpV7tdkt4AaN+UXediWU8C2HOeMPTu/mJwC58Cek1/ifN5XzJbsfDL3FJBf7Dng+xHhQt1Y5+CdGBtJs3qxdI6JoG5sBPXinDP4/Qf4+t732tG1Av93rQolhVC8zzmA5+2A3G2wdyvs3Q65W2HvNu9B33vgL8g+9Pqi60BsEsQkQnRtqN0EompDVDxEJTiv2PrlXvUgqg6EuZ/0Qi4pBEpmZib16tVj+PDhxMfHl7UFAPTq1Ys77riDrKwsEhISmDx5ctnVQGX07t2b2267jZ07d5KYmMj48eO55ZZbDihz6qmnMmLECEaPHk1JSQnTp0/nz3/+c1XtnglxnlJla04BGbv3sXlPPhlZ+WRk7SNzT0FZIsg5RLVNZHgYtWMiqBNTi9oxEbRvmMBpxzWgaWIMTerG0LRuDCmJMdSJiQj8Ab60FPJ3Q+4WyNniHMzLzuZ3/35gz89yqnGK9jnJQD2HXmdsEiQ0grgkqNvdmd5/II9Lghjve2ySMy+8enf7YkmhiixevJh77rmHsLAwIiIiePnll8tuB23atCn33XcfvXv3pkmTJnTq1Ik6depUet2NGzfmiSee4LTTTkNVOffcc7nwwgsPKNOjRw8uv/xyunXrRosWLQ6ovjI1W2mpsiWngHU78sjck8/23AK2eevot+UUst175l9SeuAVbYOEKJrUjaFNcjx92ibRoHYUDROiaVg7muSEKBJjI6gdE0F0RHiA9syrpMg5My/Y4xzU87Y7Z/C+n/duc87oc7dCafHB6wiP8h64vWfmiS0hMg4i4iAyFiJinenIOIhLhviG3kSQXO0P8kfL1TGaRWQQ8BwQDryuqk+WW94CeBNIBnYDw1U143DrTE1N1fKD7CxfvpyOHTtWZehVbu/evcTHx1NSUsKQIUO47rrrGDJkSKDDcl0w/G5CgadU2ZZT4D3L38e6HXms2ZnH2h15rNu596A6+7qxETRMiC6rr29UJ4qUxFhSEmNISYylcZ3owB/sAUo9sGcD7FgFO72v3Wuds/qCPU4yKN536O/H1IP4Bs4roYlzIE9oDLUbO+/xDZwz+Mg4CPRVjMtEZJ6qph6pnGtXCiISDrwInAlkAHNFZJqqLvMp9gzwtqqOE5HTgSeAq92KKZAefvhhvvzySwoKCjjrrLMOaCQ2prKKSkpZtiWH+RuyWJKZTUaW05C7NacAj8+ZfphAs3qxtE6K45Q29WmdHEfrpHhSEmNIToiqJgf8Um/9fKb3LH7Lge/ZGbBrDXgKf/9OXAOo3xaS2jl189F1IKYuRNf11tXX957Jew/24VYZcrTc/In1AtJVdS2AiEwALgR8k0In4A7v59nAVBfjCahnnnkm0CGYIOMpVTbt3sfSzBwWbMxi/sYslmTmUFTinPU3SIiiRf1YTmyZSNPEGJrWjfW+x9CsXgxRtQJ44PcUO1U2OVucg37OFsjZDDmZ3vfNzryDqnLEe2bfEOq2gLYDIak9JB/nJIKYxIDsTk3iZlJoCmzymc4Aepcr8xtwCU4V0xAgQUTqq+ou30IiMhIYCdC8eXPXAjYmULZmF7B8Sw4rt+Wyamsuq7bnsnrbXgq9CSCyVhhdmtbhmpNb0KN5It2bJ9KoTnRggvUUQ9Z6n4O895W75feDfd4OoFzVdHiUc6dNnRRofrLzuXbTA6tz4hrY2X2AufnTr6iCrnwDxt3ACyIyAvgO2AwcdIuDqo4BxoDTplC1YRrjXzkFxSzOyGbhpj38tmkPv2XsYVvO71UkjWpH065hPMNPasFxDRPo0DiBDo1qE1nLz/fgl5ZC1jrYvtx57fC+71x98Bl+TKJTZ1+7MTTu+vtn3/fYeiFfbx8K3EwKGUAzn+kUINO3gKpmAhcDiEg8cImqHuYGX2OCU/r2XGYs2sqnS7awclsu++/vaJUUxyltkuiaUofjm9ahfYME6sQG4G4WVcjeBJvnQ+Z8533Lb1Do0ztA3RbQoCO0PxuSOzhn/AmNnTP+iBj/x2xc4WZSmAu0E5FWOFcAVwBX+hYQkSRgt6qWAvfi3IlkTEhI376XmYu3MGORkwhE4MQW9bhzYHu6NqtLl5Q61I2NDExwOVtgy0LIXACZC51EkLfDWRYWAY1OgM5DoUl3aNgJko5zHq4yIc+1pKCqJSJyMzAL55bUN1V1qYg8AqSp6jRgAPCEiChO9dFf3YrHGH8o9pQydcFm3vhhHSu2/p4I/nHB8Qw6oRENawegHaDU4xz8186GjHnO571bnWUS5hzw2w6Epj2hSQ8nIdSKOvw6TchytUVHVWcCM8vNe9Dn8yRgkpsx+Mv69esZPHgwS5YsqZL1+fZ+Wlk2fkPg5Bd5+GDuRl77fh2b9+TTsXFtHj6/E+d0bhyYRLB7LayZ7SSCdd/93u1CUnto3d+5AmjSHRp1du7RN8bLmvmrgaPp3+hwbPwG/8spKOadnzfw5g/r2JVXRGqLRP455AQGtE/2f5cOO1bCoomwZLLTQAxQOwU6ng+tT4PWA5yndo05jNBLCp+Ohq2Lq3adjTrDOU8esZjH4+HGG2/kp59+omnTpnz88ce8++67jBkzhqKiItq2bcs777xDbGwsI0aMoF69eixYsIAePXpw3333MWzYMHbs2EGvXr0O24leRWM3XH755QwYMMDGb/ATVeXdXzbw9KyV5BaU0L99Mn89rS29WtXzbyC5W50ksOgDp2FYwpyD/0n/B21Ocx70sjt+zFEIvaQQQKtXr2b8+PG89tprXHbZZUyePJmLL76YG2+8EYD777+fN954o6wzu1WrVvHll18SHh7OrbfeSt++fXnwwQeZMWMGY8aMOeR2Khq7wZeN3+CurdkF3DPpN75fvZN+7ZIYNagDJzStfF9Wf5gqrP4cfn0F1n7jdLXcuBuc/QSccAkkNPRfLCbkhF5SqMQZvVtatWpFt27dAOjZsyfr169nyZIl3H///ezZs4e9e/dy9tlnl5UfOnQo4eHOU6ffffcdU6ZMAeC8884jMfHQT24ebuwGsPEb3KKqTPstkwemLqHYo/zzohO4qndz/1UTeUpg2VT44VnYtsR58KvvndDlMueJX2OqQOglhQDyHQshPDyc/Px8RowYwdSpU+natStjx47lm2++KSsTF3dgA19lDy4Vjd3w4INl7fc2foMLsvKKuP/jJcxYtIUezevyn8u60TLJTw20xQWw8D346X/Ok8RJx8FFr0DnS0Ouh04TeNVkmKLQlZubS+PGjSkuLua99947ZLlTTz21bPmnn35KVlbWIctmZmYSGxvL8OHDufvuu5k/f/4By3v16sW3335LVlYWJSUlTJ48+ahi7t27N99++y07d+7E4/Ewfvx4+vfvf1C8H330Efn5+eTm5jJ9+vSj2kYw+X71Ds7673d8vnQr95x9HBP/fLJ/EoIqLHgPnusCM+50Onu7/D34v1+g2zBLCMYVdqXgskcffZTevXvTokULOnfuTG5uboXlHnroIYYNG0aPHj3o37//Yft4qmjsBl82fkPVUFVe+XYt/5q1gjbJ8Yy99kSOb+KntoOCbPjkDqcRufnJcMnr0LKfNRob17k6noIbgnU8BX+rLuM3BOvvJq+whHsm/cbMxVs5r0tj/nVpF2Ij/XQOtWkOTL4esjfD6X+HPrdDWDXo6toEtYCPp2ACy8ZvOHbrd+Yx8p000rfv5d5zOjDy1Nb+aT8p9cAP/4HZT0CdpnDdLGh2ovvbNcaHJYVqbNeuXZxxxhkHzf/qq6+oX7/+Yb9r4zccm9krtnPrhAWEhwlvX9ebvu389LBXTiZMGQnrv3duKx38rDNojDF+FjJJQVVD7m6Y+vXrs3DhwkCHccyCqWpyf/vB07NW0LFRbV69uifN6sX6Z+PblsE7Q6AwFy58CbpdaW0HJmBCIilER0eza9cu6tevH3KJIVipKrt27SI6OkADwRwFVeWZz1fy4uw1nN+1CU9f0oWYSD/V4W/8Fd4f6gwMf8OXTo+kxgRQSCSFlJQUMjIy2LFjR6BDMT6io6NJSUkJdBiHpao88ekKxny3lmG9mvHYRZ0JC/PTicXqL+CDq53xCK7+CBJb+Ge7xhxGSCSFiIgIWrVqFegwTJBRVf4xfRljf1rPn05uwcPnH++/hLDoQ5h6EzToBMOnQHyyf7ZrzBGERFIw5miVlioPfLyE937dyPV9W3H/eR39V/X466vw6d+gRV8YNh6ia/tnu8ZUgqtPNIvIIBFZKSLpIjK6guXNRWS2iCwQkUUicq6b8RgD4ClVRk9ZxHu/buSm/m38mxC+ecpJCB0Gw/DJlhBMteNaUhCRcOBF4BygEzBMRMq3ot0PTFTV7jjDdb7kVjzGABSVlHL3h78xMS2DW89ox6hBx/kvISyeBN88Dl2vhKHjIKL6N8KbmsfN6qNeQLqqrgUQkQnAhcAynzIK7D9VqgNkuhiPqeF25Bbyl3fnkbYhi7vPas/Np7fz38Z3robpt0Gzk+CC/0G41dya6snNv8ymwCaf6Qygd7kyDwOfi8gtQBwwsKIVichIYCRw2D6BjDmURRl7+PM788jaV8Tzw7pzftcm/tt40T6Y+Cdn3ONL37SO7Ey15mabQkXX5OWfZhoGjFXVFOBc4B0ROSgmVR2jqqmqmrq/j39jKuujBRkMfeVnwkSY/JdT/JsQAGbeA9uXw8WvOd1XGFONuXmlkAE085lO4eDqoeuBQQCq+rOIRANJwHYX4zI1RImnlKc+W8Fr36+jd6t6vHRVD+rHRx35i1Vpwbuw8F049W/Q9uAuS4ypbty8UpgLtBORViISidOQPK1cmY3AGQAi0hGIBuwJNPOH7S0s4dqxc3nt+3Vcc3IL3r2ht/8TwtYlMOMuaHUqDDjo5jtjqiXXrhRUtUREbgZmAeHAm6q6VEQeAdJUdRpwF/CaiNyBU7U0QoOpwxxTLRUUe7hxXBpz1u/myYs7c0WvALRDFebCh9c4ndpd8oZ1fW2Chqu3QKjqTGBmuXkP+nxeBvRxMwZTsxR7Srn5/QX8sm4Xz17WjYu6B6AOX9W502j3WrhmOsQ38H8MxhwjG47ThIzSUuVvkxbx5fJtPHLB8YFJCADz33ZGTDv9fmjZNzAxGHOMLCmYkOD0Y7SUjxZs5p6zj+Pqk1sGJpCdq+Gz0dCqP/S5IzAxGPMHWFIwIeE/X6xi3M8bGHlqa/5vQJvABFFSBJNvcJ5HGPIKhNm/lwk+9lilCXqvf7+W579O54oTm3HvOR0CN6bG7Mdgy0K4/D2nO2xjgpCdypigNv23TP45YznndWnMY0M6By4hrPsOfnwOeo6AjoMDE4MxVcCSgglaW7ML+PtHi+nRvC7PXtaNcH+NhVDevt0w5c9Qvy2c/XhgYjCmilj1kQlKqsqoyYso9ij/uawbkbUCdH6z//bTvB3O2AiRcYGJw5gqYlcKJiiNn7OJb1ft4N5zO9AyKYAH4gXvwPJpcMYD0KRb4OIwpopYUjBBZ+OuffxzxjL6tK3P8N4BHNd4Zzp8OsrpxuLkWwIXhzFVyJKCCSqlpcrdk34jXISnL+3qvzGVyyvOhw9HeG8/fdVuPzUhw9oUTFB566f1zFm3m39d2oWmdWMCF8hn98K2xXDlh3b7qQkpdnpjgkb69r08/dkKBnZswKU9UwIXyOJJMO8t6HM7tD8rcHEY4wJLCiYolHhKuWviQmIiw3n84gA+j+A7rObpDwQmBmNcZNVHJiiM+X4tv2Vk88KV3WmQEKAB733bES5908ZZNiHJ/qpNtZeVV8RLs9dwZqeGDO4SwPr7T0fBtiVw1WQbVtOELFerj0RkkIisFJF0ETlo6CkReVZEFnpfq0Rkj5vxmOD06ndrySsq4Z6zjwtcEIsmwvxx0PdOaDcwcHEY4zLXrhREJBx4ETgTZ7zmuSIyzTuwDgCqeodP+VuA7m7FY4LT9twCxv60jgu7NqF9w4TABLFzNUy/HZqfAqf9PTAxGOMnbl4p9ALSVXWtqhYBE4ALD1N+GDDexXhMEHr5mzUUe5TbBrYPTAAlhfDhtRARDZe+Ye0IJuS5mRSaApt8pjO88w4iIi2AVsDXh1g+UkTSRCRtx44dVR6oqZ4y9+Tz3i8bubRHCq0C1ZXFl/9wnke48CV7HsHUCG4mhYruGdRDlL0CmKSqnooWquoYVU1V1dTk5OQqC9BUb89/nY6i3HJG28AEkP4V/PIi9BoJxw0KTAzG+JmbSSEDaOYznQJkHqLsFVjVkfGxYVceH6Zt4spezUlJjPV/AHt3wEc3QYNOcOYj/t++MQHiZlKYC7QTkVYiEolz4J9WvpCIHAckAj+7GIsJMs99tZrwMOGvpwXgKkEVpt0MBdlwyesQEcDuNIzxM9eSgqqWADcDs4DlwERVXSoij4jIBT5FhwETVPVQVUumhknfnsvUBZu55pSWNKgdgAfV5r4Oqz6Dsx6Fhsf7f/vGBJCrt1Ko6kxgZrl5D5abftjNGEzwefaL1cREhHNT/zb+3/i2ZfD5/dDuLKctwZgaxvo+MtXK0sxsZizewvV9W1EvLtK/Gy8ugMnXQ1SCc7dRoPpXMiaA7KZrU6385/NV1I6uxfX9Wvt/4188CNuXOd1YxNtdbqZmsisFU238lL6Tr1Zs56YBbagTE+HfjS+ZAnNehZP+z7qxMDWaJQVTLXhKlUc+WUZKYgzX9Wnl343vWAXTboGUXjDwH/7dtjHVjCUFUy1MTNvEiq253HtOR6Ijwv234aI8mPgnpzvsoWOhlp/bMYypZqxNwQRcbkEx//58JSe2TOTczo38t2FVp6O7HSvg6inWHbYx2JWCqQZe+mYNO/cW8cDgTv4dUS3tDVg8EU67D9qc7r/tGlONWVIwAbVp9z7e+H4dF/doSpeUuv7b8OZ58Nm90PZM6He3/7ZrTDVnScEE1JOfriA8TPjb2R38t9F9u2HiNRDfCC4eA2H2b2DMfvbfYAJmzrrdzFi8hZv6t6FRHT91Z1FaClNGwt5tcNk4iK3nn+0aEySsodkERGmp8ugny2hcJ5qRp/rxQbWf/gfpX8B5/4amPfy3XWOChF0pmICYsmAzizdnM2pQB2Ii/XQL6qa58PWj0OlCSL3eP9s0JshYUjB+l1/k4V+zVtC1WV0u6Oqn0czy98Dk6yChCZz/P+vXyJhDsOoj43fv/bqBbTmFPD+sB2Fhfjg4q8L02yB7M1w3C2L8eJeTMUGmUlcKIjJZRM4TEbuyMH9IQbGHV79byylt6tOrlZ+6e6U7AAAfD0lEQVQaeeeNhWVT4YwHoNmJ/tmmMUGqsgf5l4ErgdUi8qSI+PH+QRNKxs/ZyI7cQm49o51/NrhtGXw2GlqfBqfc5p9tGhPEKpUUVPVLVb0K6AGsB74QkZ9E5FoROWR3liIySERWiki6iIw+RJnLRGSZiCwVkfePZSdMcCgo9vDKt2vo3aoeJ7Wu7/4Gi/bBpGshqrY9j2BMJVX6v0RE6gMjgBuABcBzOEnii0OUDwdeBM4BOgHDRKRTuTLtgHuBPqp6PHD70e+CCRYfzN3EtpxCbhvop6uEz0Y7/Rpd/CrEN/DPNo0JcpVqaBaRKUAH4B3gfFXd4l30gYikHeJrvYB0VV3rXccE4EJgmU+ZG4EXVTULQFW3H/0umGBQWOLh5W/WcGLLRE72x1XCvLEwfxz0vcP6NTLmKFT27qMXVPXrihaoauohvtMU2OQznQH0LlemPYCI/AiEAw+r6mflVyQiI4GRAM2bN69kyKY6mZiWwdacAp4Z2tX9Tu9Wfgaf3AFtB8Jpf3d3W8aEmMpWH3UUkbL7+EQkUUT+7wjfqeg/X8tN1wLaAQOAYcDrvtsp+5LqGFVNVdXU5GQbJjHYFJZ4eHl2Oj1bJNKnrctXCZvnOe0IjTrD0HEQ7ucR3IwJcpVNCjeq6p79E97qnhuP8J0MoJnPdAqQWUGZj1W1WFXXAStxkoQJIZPmZZCZXcBtZ7Rz9yph91p47zKIS4IrP4SoePe2ZUyIqmxSCBOf/2ZvI/KRhqiaC7QTkVYiEglcAUwrV2YqcJp3nUk41UlrKxmTCQJFJaW8NHsN3ZrVpV+7JPc2lLcT3r0E1APDp0BCQ/e2ZUwIq2xSmAVMFJEzROR0YDxwUN2/L1UtAW72fnc5MFFVl4rIIyJygc96d4nIMmA2cI+q7jqWHTHV05T5GWzek89tA128SijaB+9fDjmZMOwDSLKLTWOOlaiWr+avoJDzJPOfgTNw2go+B15XVY+74R0sNTVV09IOdcOTqU6KPaWc9sw31I+LZOpf+7iTFEo98MFwWPkpXP4OdDy/6rdhTAgQkXmHuTGoTKXuPlLVUpynml/+o4GZmuOjBZvJyMrnHxcc795Vwqz7YOVMOOdflhCMqQKVfU6hHfAEzkNoZaOhqKofO8I3waTEU8qLs9Pp3LQOp3dw6cGxtLfg11fgpP+D3iPd2YYxNUxl2xTewrlKKMFpGH4b50E2Yyr08cJMNuzax61u3XG07juYebfzLMKZj1b9+o2poSqbFGJU9SucNogNqvowYI+JmgqVeEp5YXY6nRrXZmBHF64Sdq+FiX+Cem3g0jch3HqAN6aqVPa/qcDb2LxaRG4GNgPWmYyp0PRFmazbmccrw3tW/VVCQTa8f4Xz+coJEF2natdvTA1X2SuF24FY4FagJzAcuMatoEzw8pQqz3+dTodGCZzVqYqfFSj1wKTrYfcauOwdqGdNWsZUtSNeKXgfVLtMVe8B9gLXuh6VCVqfLMpk7Y48XrrKhVHVPn8A0r+Awf+FVv2qdt3GGKASVwreZxF6iuu9mJlgV+q9SmjfMJ5Bxzeq2pUveBd+eRF63wSpdl5ijFsq26awAPhYRD4E8vbPVNUprkRlgtLMJVtI376X54d1r9qrhK2L4ZM7ofUAOOuxqluvMeYglU0K9YBdHHjHkQKWFAzgvUr4Kp22DeI5t3PjqltxYS58OAJi68HFr9udRsa4rLJPNNv1ujmsWUu3snJbLs9d0Y3wqrpKUIXptzu3oF7zCcRbt+nGuK2yTzS/xcFjIaCq11V5RCbolJYqz321mtbJcQzu0qTqVjzvLVgyCU5/AFr2qbr1GmMOqbLX4p/4fI4GhnDw2Aimhpq1dCsrtuby7OVdq+4qYcsi+HQ0tDkD+t5ZNes0xhxRZauPJvtOi8h44EtXIjJBZdfeQh74eCkdGiVwflVdJRTk+LQjjIGwyj5OY4z5o4611a4dYIMl13CqyqjJi8gpKObdG3pRK7wKDt6qMP02yFoPIz5xRlEzxvhNpf6LRSRXRHL2v4DpwKhKfG+QiKwUkXQRGV3B8hEiskNEFnpfNxz9LphAeX/ORr5cvp1RgzrQoVHtqllp2huwdAqcfj+0OKVq1mmMqbTKVh8lHO2KvU9CvwiciTMW81wRmaaqy8oV/UBVbz7a9ZvASt++l0c/WUa/dklce0rLqlnp8ukw82/Q9kzoc3vVrNMYc1Qqe6UwRETq+EzXFZGLjvC1XkC6qq5V1SJgAnDhsYdqqouiklJu/2ABMRHhPDO0a9U8qLbqc/jwWmjaE4a+Ze0IxgRIZf/zHlLV7P0TqroHeOgI32kKbPKZzvDOK+8SEVkkIpNEpFlFKxKRkSKSJiJpO3bsqGTIxi3PfrmKJZtzePKSLjSsHX3kLxzJmtnOkJoNj4erPoSoo74wNcZUkcomhYrKHanqqaLTx/LPOkwHWqpqF5y7mcZVtCJVHaOqqaqampxsDzAF0s9rdvHKt2u44sRmnF0V/Rut/xHGD4OkdnD1RxBT94+v0xhzzCqbFNJE5D8i0kZEWovIs8C8I3wnA/A980+h3LMNqrpLVQu9k6/hdMttqqnsfcXcNXEhLerF8sDgTn98hZvmwPuXQd3mcPVU5xZUY0xAVTYp3AIUAR8AE4F84K9H+M5coJ2ItBKRSOAKYJpvARHx7STnAmB5JeMxfpZTUMzN4+ezLbeQ/17RnbioP9gH0eb58O4lEN8ArplmXVgYU01U9u6jPOCgW0qP8J0S7yhts4Bw4E1VXSoijwBpqjoNuFVELsAZ+3k3MOJotmH8Y93OPG4YN5cNu/bx+JAT6NbsGKt4ivIg/SvnLqMVMyCuPlwzHRKquJttY8wxE9WDujQ6uJDIF8BQbwMzIpIITFDVs12O7yCpqamalpbm783WWN+u2sEt788nPEx46aqenNym/tGtoCAbVs2C5dNg9ZdQkg8x9aDDudB/lFN1ZIxxnYjMU9XUI5WrbB1A0v6EAKCqWSJiYzSHMFXljR/W8fjM5bRvmMBrf0qlWb3Yw30BcjJh21LYvtR537YUdq6C0hKIbwTdh0PH86FFH+sC25hqqrL/maUi0lxVNwKISEsq6DXVhIaCYg/3fbSYKfM3c84JjXhmaNdDtyFsngdz34CVMyE/6/f5dZpBg05w3LnQ/mxommrPHhgTBCqbFP4O/CAi33qnTwVGuhOSCaSdewu5YVwaCzft4c4z23PzaW0PfjitOB+WTIG5r0HmAoiMh04XQpPuzrMGDTrZraXGBKnKNjR/JiKpOIlgIfAxzh1IJoSs25nHiLfmsC2ngFeG92TQCeUagPdshDljnPGS87Mg6Tg49xnocjlEV1HfR8aYgKrsIDs3ALfhPGuwEDgJ+JkDh+c0QWzBxiyuH+c04L9/40n0aJ74+8KCHPjhP/Dzi1DqgY6D4cQboWVfkCoci9kYE3CVrT66DTgR+EVVTxORDsA/3AvL+NMXy7Zxy/j5NKwdzdhre9EqKc5ZUOpxrgq+/ifkbYcuV8AZD0CdlMAGbIxxTWWTQoGqFogIIhKlqitE5DhXIzN+8c4vG3jo4yV0blqHN0acSFJ8lLNg3Xfw2X2wbTE06w3DJkCKPXBuTKirbFLIEJG6wFTgCxHJwobjDGqqyr9mreSlb9ZwRocGPH9ld2Ija0FpKUz9CyyaAHWaw6VvwfFDrJrImBqisg3NQ7wfHxaR2UAd4DPXojKue+6r1bz0zRqG9WrOoxce//uoafPedBJCn9thwGiIiAlsoMYYvzrqJ4hU9dsjlzLV2cS5m/jvl6u5tGcKjw85Adl/FZC1AT5/EFqfBgMftqsDY2oge5qohpm9cjv3frSYfu2SeOLizr8nBFWYdjNIGFzwvCUEY2oo62ugBlmUsYe/vjefDo0SeHl4TyLCfc4J5r3lNC4P/i/UrXCsI2NMDWBXCjXExl37uG7sXBJjI3lrxInE+3ZbkbUBPn8AWg+AniMCFKExpjqwK4UaYHdeEde8NYeSUmXCdb1o4DuEpipMu8X5bNVGxtR4lhRCXEGxh+vHzSVzTz7v3dCbtg3iDywwbyys+xYGP2vdWBtj3K0+EpFBIrJSRNJF5JCD9IjIpSKi3v6VTBV688d1LNi4h+eu6EZqy3LDXe7ZCJ/fD61OhZ7XBiZAY0y14lpSEJFw4EXgHKATMExEDhrYV0QSgFuBX92KpaYqLPEw9sf19GuXxKATGh+4cH+1kSpc8IJVGxljAHevFHoB6aq6VlWLgAnAhRWUexR4GihwMZYaadrCTLbnFjLy1NYHL1w8CdZ+A2f+AxJb+D02Y0z15GZSaAps8pnO8M4rIyLdgWaq+snhViQiI0UkTUTSduzYUfWRhiBV5bXv19KhUQJ92yYduLBwL3zxADTuBqnXBSZAY0y15GZSqKg+omy0NhEJA54F7jrSilR1jKqmqmpqcnJyFYYYur5dtYNV2/Yy8tTWvz+gtt/3/4bcLXDO0xAWHpgAjTHVkptJIQPwfQoqhQM70UsATgC+EZH1OGM0TLPG5qrx2vdraVQ7msFdmhy4YNca+PkFpxvs5r0DE5wxptpyMynMBdqJSCsRiQSuAKbtX6iq2aqapKotVbUl8AtwgaqmuRhTjbBkczY/pu/i2j4tiaxV7lc86+8QHum0JRhjTDmuJQVVLQFuBmYBy4GJqrpURB4RkQvc2q6B179fS3xULYb1LvfcweovYNWn0P9vkNCo4i8bY2o0Vx9eU9WZwMxy8x48RNkBbsZSU2TuyWf6oi1ce0pLakdH/L6gpAg+Gw3120LvvwQuQGNMtWZPNIeYN39YB8C1fVsduODXV2BXOlw1CWpFBiAyY0wwsA7xQkh2fjHj52xkcJfGNK3rMzhO7lb49ilofw60OzNwARpjqj1LCiFkwpyN5BV5uLFfuYfVvnwYPEVw9mMBicsYEzwsKYSIopJS3vpxPX3a1ueEpnV+X7DhZ/htPJx8M9RvE7gAjTFBwZJCiPhkUSZbcwoOvEoo3AtTb3J6P+13xGcEjTHGGppDxfg5G2mdHEf/9j5PfM+6zxlA59pPISr+0F82xhgvu1IIAet35jF3fRZDezb7vUuLlZ/B/HHQ5zZocXJgAzTGBA1LCiFgyvwMwgSGdPf2N5i3E6bdDA07w2n3BTY4Y0xQseqjIFdaqkyev5m+7ZJpVCfaGR9h+m1QkA1/mga1ogIdojEmiNiVQpD7Ze0uNu/J59KeKc6Mhe/Bik/gjIeg4UFjGhljzGFZUghyk+ZlkBBdi7M6NYSs9fDpKGjZD076v0CHZowJQpYUgtjewhI+XbKVwV2aEB0OfPQXkDC46CUIs1+tMeboWZtCEJu5eAv5xR6n6uiXl2HjTzDkVee5BGOMOQZ2OhnEJs3LoHVSHD0SC+CbJ6D9IOhyeaDDMsYEMUsKQWrjrn3MWbebS3qmIF894u3b6HEoP/SmMcYcBUsKQWry/AxE4LJG2+C3952GZevbyBjzB7maFERkkIisFJF0ERldwfKbRGSxiCwUkR9ExO6hrATn2YQM+rWpR/IPD0B8Izj17kCHZYwJAa4lBREJB14EzgE6AcMqOOi/r6qdVbUb8DTwH7fiCSW/rttNRlY+tyXPh83zYODDEJUQ6LCMMSHAzSuFXkC6qq5V1SJgAnChbwFVzfGZjAPUxXhCxuT5GTSIKqbHquegaao1Lhtjqoybt6Q2BTb5TGcAvcsXEpG/AncCkcDpFa1IREYCIwGaN6/Zt1vmFZYwc/EWXmowC9m5DYaNt2cSjDFVxs2jSUW3wRx0JaCqL6pqG2AUcH9FK1LVMaqaqqqpycnJFRWpMT5dspUGxRmcuvtD6HYVpPQMdEjGmBDiZlLIAJr5TKcAmYcpPwG4yMV4gt6m3ft4cXY6j8eOR2pFO/0bGWNMFXIzKcwF2olIKxGJBK4ApvkWEJF2PpPnAatdjCeozVm3mwtf/JGOe3/hFE8a0v8eSGgY6LCMMSHGtTYFVS0RkZuBWUA48KaqLhWRR4A0VZ0G3CwiA4FiIAu4xq14gtnEtE38/aPFtKsrPBc+Hmq1gd5/CXRYxpgQ5GrfR6o6E5hZbt6DPp9vc3P7wc5Tqjz12QrGfLeWvm2TeCPpfSIWboARn0CtyECHZ4wJQdYhXjWVW1DM7RMW8tWK7fzp5BY82CGTWuPHwsk3Q8u+gQ7PGBOiLClUM+t35vHJokwmpmWweU8+j1x4PH/qWhtevhSSO8DpDwQ6RGNMCLOkUA1kZO1jxqItTF+UyZLNzvN8qS0SeeLizvRpmwSTroe8HTBsAkREBzhaY0wos6QQIKWlyqylW3n9h3XM25AFQNdmdbn/vI6c27kxTerGOAWXTIYlk+C0+6FJtwBGbIypCSwp+FmJp5RPFm3hxdnprN6+l1ZJcfxt0HEM7tyE5vVjDyycuxVm3AVNe0LfOwITsDGmRrGk4CdFJaV8tCCDl75Zw4Zd+ziuYQLPD+vOuZ0bEx5WwcPfqjDtFigucEZTC7dflTHGfXakcVlhiYeJaRm8PDudzOwCuqTUYczVPRnYsSFhFSWD/eaPg9WfwzlPQ1K7Q5czxpgqZEnBJfuTwUuz09mSXUDPFok8cUkXTm2XhBxpdLT0r+DT0dCqP5x4o38CNsYYLClUucISDx96k0GmNxn869Ku9Glb/8jJAGD5dJh0HSQdB5e8YT2gGmP8ypJCFfp86VYenraUzOwCejSvy1OXdqFv20pcGez32wcw9S/QpDsMnwQxie4GbIwx5VhSqCIT525i9JRFdGhUmycv6UK/ylQT+Up7Ez6503laedh4G0nNGBMQlhSqwBs/rOPRT5bRr10Sr17dk9jIo/yx/vg/+OIBaHc2XDYOImLcCdQYY47AksIfoKr898vVPPfVas45oRH/vaIbUbXCj2YF8M2T8O2T0OkiuPg16+jOGBNQlhSOUWmp8uiMZbz143qG9kzhiYs7Uyv8KBqFi/Nh+u2waAJ0Gw4X/A/CjiKhGGOMCywpHIMSTyn3TlnMh/MyuLZPSx44r9PhnzkoLzsDJlwFWxbCgPvg1HvsLiNjTLXg6pFIRAaJyEoRSReR0RUsv1NElonIIhH5SkRauBlPVVBV7v7wNz6cl8HtA9vx4OCjTAgbfoIxA2DXGrhiPAwYZQnBGFNtuHY0EpFw4EXgHKATMExEOpUrtgBIVdUuwCTgabfiqSpv/7yBqQszuevM9tw+sH3l7zBShbmvw7jzIao23PgVdDjX3WCNMeYouXmK2gtIV9W1qloETAAu9C2gqrNVdZ938hcgxcV4/rBFGXt4bMZyBnZswM2nt638F3O3wvRbnc7t2pwON34Nyce5F6gxxhwjN9sUmgKbfKYzgN6HKX898GlFC0RkJDASoHnz5lUV31HJzi/mr+/PJzkhimeGdj30FUJpKexcCRt/cV6bfoGs9c6yfnfDafdZg7IxptpyMylUdNTUCguKDAdSgf4VLVfVMcAYgNTU1ArX4SZVZfTkRWzZU8AHfz6ZurEV3DZaXACzH4P5b0PBHmdeXDI06+30X9TqVGjcxb+BG2PMUXIzKWQAzXymU4DM8oVEZCDwd6C/qha6GM8xe+eXDXy6ZCv3nduBni0q6Hpi62KYfCPsWA4nXAJtzoDmJ0G91nA0TzUbY0yAuZkU5gLtRKQVsBm4ArjSt4CIdAdeBQap6nYXYzlmizOy+ecnyzmjQwNu6Nv6wIWlHvjpefj6nxBbD66aDO0GBiZQY4ypAq4lBVUtEZGbgVlAOPCmqi4VkUeANFWdBvwLiAc+9NbRb1TVC9yK6WjlFDjtCEnxkTwztOuBt55mbXA6r9vwI3Q8HwY/B3H1AxesMcZUAVcfXlPVmcDMcvMe9PlcbU+r97cjbN6Tz8Q/n0RinLcdobQUFr4Hn93rTF/0MnQdZtVExpiQYE80H8KEuZuYuXgro8/pQM8W9ZyZm+bCZ6Ng8zxofgoMeRkSWwY0TmOMqUqWFCqQvj2Xf0xfSr92SYzs1xpyMuHLh2HRBxDfyBkzufNl9iSyMSbkWFIop7DEwy3jFxIbWYt/X9SesB+ege//4zQq97sL+t4JUfGBDtMYY1xhSaGcpz9biWfrUqZ0W0ODsbdCbiZ0vADOetSqiowxIc+Swn7ZGaz5eiyXLviAB6I2wopwaHMaXPyq8+CZMcbUADUnKSyaCHNec7qYkHCnPUDCQcKgMAfNSKMNyrKI4yg+4ykiulwC8cmBjtoYY/yq5iSFsFoQGeu0DWgplBSBeqDUg4bVYkqdP/Hyru689JdLiWho4yMbY2qmmpMUTrjYeVXgTe8Yy49edALtLSEYY2qwmpMUyinxlPLL2t3MXLKFSWkZDOzYkOG9A9MDqzHGVBc1KikUe0r5ac0uPl28hVlLt5K1r5jYyHDO6dyIh88/vvID5hhjTIiqMUnhg7kbeXzmCrLzi4mLDGdgp4acc0JjBhyXTHSEjW9gjDFQg5JCozoxnN6hAed2bky/dkmWCIwxpgI1Jin0b59M//Z2i6kxxhyOdd5jjDGmjCUFY4wxZVxNCiIySERWiki6iIyuYPmpIjJfREpE5FI3YzHGGHNkriUFEQkHXgTOAToBw0SkU7liG4ERwPtuxWGMMaby3Gxo7gWkq+paABGZAFwILNtfQFXXe5eVuhiHMcaYSnKz+qgpsMlnOsM776iJyEgRSRORtB07dlRJcMYYYw7mZlKo6PFgPZYVqeoYVU1V1dTkZLut1Bhj3OJmUsgAmvlMpwCZLm7PGGPMH+Rmm8JcoJ2ItAI2A1cAV/7Rlc6bN2+niGw4xq8nATv/aAxBqKbuN9Tcfbf9rlkqs98tKrMiUT2mGp1KEZFzgf8C4cCbqvqYiDwCpKnqNBE5EfgISAQKgK2qeryL8aSpaqpb66+uaup+Q83dd9vvmqUq99vVbi5UdSYws9y8B30+z8WpVjLGGFMN2BPNxhhjytS0pDAm0AEESE3db6i5+277XbNU2X672qZgjDEmuNS0KwVjjDGHYUnBGGNMmRqTFI7UY2uoEJE3RWS7iCzxmVdPRL4QkdXe98RAxugGEWkmIrNFZLmILBWR27zzQ3rfRSRaROaIyG/e/f6Hd34rEfnVu98fiEhkoGN1g4iEi8gCEfnEOx3y+y0i60VksYgsFJE077wq+zuvEUmhkj22hoqxwKBy80YDX6lqO+Ar73SoKQHuUtWOwEnAX72/41Df90LgdFXtCnQDBonIScBTwLPe/c4Crg9gjG66DVjuM11T9vs0Ve3m82xClf2d14ikgE+PrapaBOzvsTXkqOp3wO5ysy8Exnk/jwMu8mtQfqCqW1R1vvdzLs6Boikhvu/q2OudjPC+FDgdmOSdH3L7DSAiKcB5wOveaaEG7PchVNnfeU1JClXWY2uQaqiqW8A5eAINAhyPq0SkJdAd+JUasO/eKpSFwHbgC2ANsEdVS7xFQvXv/b/A34D9Xe/Xp2bstwKfi8g8ERnpnVdlf+euPtFcjVRZj62mehOReGAycLuq5jgnj6FNVT1ANxGpi9NtTMeKivk3KneJyGBgu6rOE5EB+2dXUDSk9turj6pmikgD4AsRWVGVK68pVwo1vcfWbSLSGMD7vj3A8bhCRCJwEsJ7qjrFO7tG7DuAqu4BvsFpU6krIvtP+kLx770PcIGIrMepDj4d58oh1PcbVc30vm/HOQnoRRX+ndeUpFDWY6v3boQrgGkBjsmfpgHXeD9fA3wcwFhc4a1PfgNYrqr/8VkU0vsuIsneKwREJAYYiNOeMhvYP+55yO23qt6rqimq2hLn//lrVb2KEN9vEYkTkYT9n4GzgCVU4d95jXmiuaIeWwMckitEZDwwAKcr3W3AQ8BUYCLQHGdc7KGqWr4xOqiJSF/ge2Axv9cx34fTrhCy+y4iXXAaFsNxTvImquojItIa5wy6HrAAGK6qhYGL1D3e6qO7VXVwqO+3d/8+8k7WAt739j5dnyr6O68xScEYY8yR1ZTqI2OMMZVgScEYY0wZSwrGGGPKWFIwxhhTxpKCMcaYMpYUjPEjERmwv0dPY6ojSwrGGGPKWFIwpgIiMtw7TsFCEXnV2+ncXhH5t4jMF5GvRCTZW7abiPwiIotE5KP9fdmLSFsR+dI71sF8EWnjXX28iEwSkRUi8p7UhA6aTNCwpGBMOSLSEbgcp+OxboAHuAqIA+arag/gW5ynxQHeBkapahecJ6r3z38PeNE71sEpwBbv/O7A7Thje7TG6cfHmGqhpvSSaszROAPoCcz1nsTH4HQwVgp84C3zLjBFROoAdVX1W+/8ccCH3v5pmqrqRwCqWgDgXd8cVc3wTi8EWgI/uL9bxhyZJQVjDibAOFW994CZIg+UK3e4PmIOVyXk2xePB/s/NNWIVR8Zc7CvgEu9/dXvH/+2Bc7/y/4eOK8EflDVbCBLRPp5518NfKuqOUCGiFzkXUeUiMT6dS+MOQZ2hmJMOaq6TETuxxndKgwoBv4K5AHHi8g8IBun3QGcropf8R701wLXeudfDbwq/9/OHdsACIVAAM31rudCzmyPzc/VxkRt3huAQHWBguRYNfYPx4BHfEmFm5KcM7P93Qe8yfkIgLIpAFA2BQBKKABQQgGAEgoAlFAAoC4oFo/9H7ks8AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model9_out.history[\"acc\"])\n",
    "plt.plot(model8_out.history[\"acc\"])\n",
    "plt.title(\"model training accuracy\")\n",
    "plt.legend([\"sigmoid\",\"hard_sigmoid\"],loc=\"best\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提高learning rate 十倍後，可以看到兩個的準確度都超過90%了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 結論\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 不同的模型有自己的最佳參數，而不同型態的數據也有適合自己的模型，所以在做學習前，要確定自己的資料是長怎樣，再進行分析，會學習的比較好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
